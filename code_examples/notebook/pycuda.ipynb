{
 "metadata": {
  "name": "pycuda"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "PyCUDA\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1. Print device properties"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import pycuda.driver as cuda\n",
      "\n",
      "all_attrs = False\n",
      "\n",
      "cuda.init()\n",
      "ngpu = cuda.Device.count()\n",
      "dev_list = [cuda.Device(i) for i in range(ngpu)]\n",
      "name_list = list(set([dev.name() for dev in dev_list]))\n",
      "dev_group = dict(zip(name_list, [{'id':[]}]*len(name_list)))\n",
      "\n",
      "for i, dev in enumerate(dev_list):\n",
      "    dev_group[dev.name()]['id'].append(i)\n",
      "\n",
      "print('Total devices: %d' % ngpu)\n",
      "for name, attrs in dev_group.iteritems():\n",
      "    print \"%s: %s\" % (name, attrs['id'])\n",
      "          \n",
      "    dev = cuda.Device(attrs['id'][0])\n",
      "    cuattr = cuda.device_attribute\n",
      "    print \"  Compute capability: \\t\\t%d.%d\" % dev.compute_capability()\n",
      "    print \"  Global memory: \\t\\t%1.2f GBytes\" % (dev.total_memory()/(1024**3))\n",
      "    \n",
      "    if all_attrs:\n",
      "        for attr, value in dev.get_attributes().iteritems():\n",
      "            print(\"  %s: %s\" % (attr, value))\n",
      "    else:\n",
      "        print \"  Max shared memory / block: \\t%1.2f KBytes\" % (dev.get_attribute(cuattr.MAX_SHARED_MEMORY_PER_BLOCK)/1024)\n",
      "        print \"  Memory ECC: \\t\\t\\t%s\" % ('off' if dev.get_attribute(cuattr.ECC_ENABLED) == 0 else 'on')\n",
      "        bandwidth = dev.get_attribute(cuattr.MEMORY_CLOCK_RATE) * dev.get_attribute(cuattr.GLOBAL_MEMORY_BUS_WIDTH) * 2\n",
      "        print \"  Memory Bandwidth: \\t\\t%1.2f GB/s\" % (bandwidth/(1000**3))\n",
      "        print \"  Multiprocessor: \\t\\t%d\" % dev.get_attribute(cuattr.MULTIPROCESSOR_COUNT)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total devices: 4\n",
        "Tesla M2090: [0, 1, 2, 3]\n",
        "  Compute capability: \t\t2.0\n",
        "  Global memory: \t\t6.00 GBytes\n",
        "  Max shared memory / block: \t48.00 KBytes\n",
        "  Memory ECC: \t\t\toff\n",
        "  Memory Bandwidth: \t\t1.42 GB/s\n",
        "  Multiprocessor: \t\t16\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2. Add two vectors"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2.1. Automatic init"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import numpy as np\n",
      "import pycuda.driver as cuda\n",
      "import pycuda.autoinit\n",
      "from pycuda.compiler import SourceModule\n",
      "\n",
      "kernels = \"\"\"\n",
      "__global__ void vecsum(int nx, double* a, double* b, double* c) {\n",
      "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
      "\n",
      "    if( idx < nx ) {\n",
      "        c[idx] = a[idx] + b[idx];\n",
      "    }\n",
      "}\n",
      "\"\"\"\n",
      "\n",
      "mod = SourceModule(kernels)\n",
      "vecsum = mod.get_function(\"vecsum\")\n",
      "\n",
      "nx = 100\n",
      "a = np.random.rand(nx)\n",
      "b = np.random.rand(nx)\n",
      "c = a + b\n",
      "\n",
      "a_gpu = cuda.to_device(a)\n",
      "b_gpu = cuda.to_device(b)\n",
      "c_gpu = cuda.mem_alloc(c.nbytes)\n",
      "c_from_gpu = np.zeros_like(c)\n",
      "\n",
      "vecsum(np.int32(nx), a_gpu, b_gpu, c_gpu, block=(256,1,1), grid=(nx//256+1,1))\n",
      "cuda.memcpy_dtoh(c_from_gpu, c_gpu)\n",
      "\n",
      "print np.linalg.norm(c - c_from_gpu) == 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2.2. Manual init"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import numpy as np\n",
      "import pycuda.driver as cuda\n",
      "from pycuda.compiler import SourceModule\n",
      "\n",
      "kernels = \"\"\"\n",
      "__global__ void vecsum(int nx, double* a, double* b, double* c) {\n",
      "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
      "\n",
      "    if( idx < nx ) {\n",
      "        c[idx] = a[idx] + b[idx];\n",
      "    }\n",
      "}\n",
      "\"\"\"\n",
      "\n",
      "cuda.init()\n",
      "ngpu = cuda.Device.count()\n",
      "gpu0 = cuda.Device(0)\n",
      "ctx0 = gpu0.make_context()\n",
      "\n",
      "mod = SourceModule(kernels)\n",
      "vecsum = mod.get_function(\"vecsum\")\n",
      "\n",
      "nx = 100\n",
      "a = np.random.rand(nx)\n",
      "b = np.random.rand(nx)\n",
      "c = a + b\n",
      "\n",
      "a_gpu = cuda.to_device(a)\n",
      "b_gpu = cuda.to_device(b)\n",
      "c_gpu = cuda.mem_alloc(c.nbytes)\n",
      "c_from_gpu = np.zeros_like(c)\n",
      "\n",
      "vecsum(np.int32(nx), a_gpu, b_gpu, c_gpu, block=(256,1,1), grid=(nx//256+1,1))\n",
      "cuda.memcpy_dtoh(c_from_gpu, c_gpu)\n",
      "\n",
      "print np.linalg.norm(c - c_from_gpu) == 0\n",
      "\n",
      "ctx0.pop()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2.3. Complex vectors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import numpy as np\n",
      "import pycuda.driver as cuda\n",
      "import pycuda.autoinit\n",
      "from pycuda.compiler import SourceModule\n",
      "\n",
      "kernels = \"\"\"\n",
      "#include <pycuda-complex.hpp>\n",
      "#define CMPLX pycuda::complex<double>\n",
      "\n",
      "__global__ void vecsum(int nx, CMPLX* a, CMPLX* b, CMPLX* c) {\n",
      "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
      "\n",
      "    if( idx < nx ) {\n",
      "        c[idx] = a[idx] + b[idx];\n",
      "    }\n",
      "}\n",
      "\"\"\"\n",
      "\n",
      "mod = SourceModule(kernels)\n",
      "vecsum = mod.get_function(\"vecsum\")\n",
      "\n",
      "nx = 100\n",
      "a = np.random.rand(nx) + 1j*np.random.rand(nx)\n",
      "b = np.random.rand(nx) + 1j*np.random.rand(nx)\n",
      "c = a + b\n",
      "\n",
      "a_gpu = cuda.to_device(a)\n",
      "b_gpu = cuda.to_device(b)\n",
      "c_gpu = cuda.mem_alloc(c.nbytes)\n",
      "c_from_gpu = np.zeros_like(c)\n",
      "\n",
      "vecsum(np.int32(nx), a_gpu, b_gpu, c_gpu, block=(256,1,1), grid=(nx//256+1,1))\n",
      "cuda.memcpy_dtoh(c_from_gpu, c_gpu)\n",
      "\n",
      "print np.linalg.norm(c - c_from_gpu) == 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "stuff"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = set(['a', 'a', 'a', 'b'])\n",
      "np.random.randn\n",
      "b = np.random.rand(10) + 1j*np.random.rand(10)\n",
      "print b\n",
      "print b.dtype\n",
      "print b.real\n",
      "print b.imag"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.15717045+0.81121261j  0.11357698+0.26763649j  0.57006540+0.6096061j\n",
        "  0.20646010+0.46624418j  0.71938264+0.19416281j  0.27286338+0.11270209j\n",
        "  0.47386494+0.58754733j  0.39442079+0.25562838j  0.43368586+0.94497926j\n",
        "  0.11904731+0.58287348j]\n",
        "complex128\n",
        "[ 0.15717045  0.11357698  0.5700654   0.2064601   0.71938264  0.27286338\n",
        "  0.47386494  0.39442079  0.43368586  0.11904731]\n",
        "[ 0.81121261  0.26763649  0.6096061   0.46624418  0.19416281  0.11270209\n",
        "  0.58754733  0.25562838  0.94497926  0.58287348]\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}